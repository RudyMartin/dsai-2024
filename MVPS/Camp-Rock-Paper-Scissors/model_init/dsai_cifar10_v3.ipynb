{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RudyMartin/dsai-2024/blob/main/MVPS/Camp-Rock-Paper-Scissors/model_init/dsai_cifar10_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBQIwnj7m3k"
      },
      "source": [
        "CIFAR10 Version #3 with suggested changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdxLGuN58vC3"
      },
      "source": [
        "### Model Overview\n",
        "\n",
        "#### Data Loading and Normalization:\n",
        "- Uses `torchvision` to load CIFAR-10 dataset.\n",
        "- Applies normalization to transform the images.\n",
        "\n",
        "#### Model Architecture:\n",
        "- A simple Convolutional Neural Network (CNN) with two convolutional layers followed by three fully connected layers.\n",
        "- The network uses ReLU activations and max pooling.\n",
        "\n",
        "#### Training:\n",
        "- Uses `CrossEntropyLoss` and SGD with momentum for optimization.\n",
        "- Training loop runs for 2 epochs, iterating over the dataset.\n",
        "\n",
        "#### Evaluation:\n",
        "- Model accuracy is computed on the test dataset.\n",
        "- The script prints the accuracy for each class and the overall accuracy.\n",
        "\n",
        "### Suggestions for Improvement\n",
        "\n",
        "#### Increase Model Complexity:\n",
        "- **More Convolutional Layers**: Add more convolutional layers to capture more complex patterns.\n",
        "- **Batch Normalization**: Add batch normalization layers to improve training stability and speed.\n",
        "- **Dropout**: Add dropout layers to reduce overfitting.\n",
        "\n",
        "#### Data Augmentation:\n",
        "- Apply data augmentation techniques (e.g., random horizontal flip, random crop) to increase the diversity of\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQrdP-_8uPT"
      },
      "source": [
        "### Key Changes in this version\n",
        "\n",
        "#### Model Architecture:\n",
        "- Added an additional convolutional layer.\n",
        "- Included batch normalization and dropout layers.\n",
        "\n",
        "#### Data Augmentation:\n",
        "- Added random cropping and horizontal flipping to the training data.\n",
        "\n",
        "#### Optimizer:\n",
        "- Switched to the Adam optimizer for better performance.\n",
        "\n",
        "#### Learning Rate Scheduler:\n",
        "- Added a learning rate scheduler to adjust the learning rate during training.\n",
        "\n",
        "#### Training Epochs:\n",
        "- Increased the number of training epochs to 50.\n",
        "\n",
        "#### Additional Validation Metrics:\n",
        "- Output specific and aggregate metrics to csv for added analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFn2q6kJ7WVL",
        "outputId": "369637ec-484d-4cee-c8b0-96a3ce23e72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 66669445.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[Epoch 1, Batch 200] loss: 1.817\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Just normalization for testing\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = ImprovedNet()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):  # Increase number of epochs to 50 , demo using 5\n",
        "    running_loss = 0.0\n",
        "    net.train()  # Set the model to training mode\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:  # Print every 200 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "    scheduler.step()\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save the trained model\n",
        "PATH = './improved_cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# Testing loop\n",
        "correct = 0\n",
        "total = 0\n",
        "net.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "# Accuracy for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtPViLn87lEu"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLHJ-kGN7-zW"
      },
      "outputs": [],
      "source": [
        "# Assuming the rest of your code has executed and you have your predictions and true labels\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming `net` is your trained model and `testloader` is your DataLoader for the test dataset\n",
        "# Make sure your model is in evaluation mode\n",
        "net.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcC5jVL8Aqs"
      },
      "source": [
        "Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVgtafHj8FWV"
      },
      "outputs": [],
      "source": [
        "# Assuming the rest of your code has executed and you have your predictions and true labels\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, balanced_accuracy_score, matthews_corrcoef, hamming_loss, jaccard_score, cohen_kappa_score, classification_report\n",
        "import pandas as pd\n",
        "# import torch\n",
        "\n",
        "# Assuming `net` is your trained model and `testloader` is your DataLoader for the test dataset\n",
        "# Make sure your model is in evaluation mode\n",
        "# net.eval()\n",
        "\n",
        "# all_preds = []\n",
        "# all_labels = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for data in testloader:\n",
        "#         images, labels = data\n",
        "#         outputs = net(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         all_preds.extend(predicted.cpu().numpy())\n",
        "#         all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert all_preds and all_labels to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Ensure `classes` is a list of strings representing the class names\n",
        "#classes = [str(cls) for cls in classes]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "# conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Initialize the metrics dictionary\n",
        "metrics = {\n",
        "    'Class': [],\n",
        "    'TP': [],\n",
        "    'FN': [],\n",
        "    'FP': [],\n",
        "    'TN': [],\n",
        "    'Recall': [],\n",
        "    'Precision': [],\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Specificity': [],\n",
        "    'MCC': [],\n",
        "    'Jaccard Index': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each class\n",
        "for i, class_label in enumerate(classes):\n",
        "    TP = conf_matrix[i, i]\n",
        "    FN = conf_matrix[i, :].sum() - TP\n",
        "    FP = conf_matrix[:, i].sum() - TP\n",
        "    TN = conf_matrix.sum() - (TP + FN + FP)\n",
        "\n",
        "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
        "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if TP + TN + FP + FN != 0 else 0\n",
        "    f1 = f1_score(all_labels, all_preds, labels=[i], average=None)[0]\n",
        "    specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    jaccard = jaccard_score(all_labels, all_preds, labels=[i], average=None)[0]\n",
        "\n",
        "    metrics['Class'].append(class_label)\n",
        "    metrics['TP'].append(TP)\n",
        "    metrics['FN'].append(FN)\n",
        "    metrics['FP'].append(FP)\n",
        "    metrics['TN'].append(TN)\n",
        "    metrics['Recall'].append(recall)\n",
        "    metrics['Precision'].append(precision)\n",
        "    metrics['Accuracy'].append(accuracy)\n",
        "    metrics['F1 Score'].append(f1)\n",
        "    metrics['Specificity'].append(specificity)\n",
        "    metrics['MCC'].append(mcc)\n",
        "    metrics['Jaccard Index'].append(jaccard)\n",
        "\n",
        "# Convert metrics dictionary to DataFrame\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "# Show the DataFrame with all metrics\n",
        "print(df_metrics)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_metrics.to_csv('df_metrics_20240805.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVbogvTZBOAr"
      },
      "source": [
        "Aggregate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, accuracy_score, balanced_accuracy_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert all_preds and all_labels to numpy arrays if they are not already\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Binarize the labels for ROC-AUC calculation\n",
        "all_labels_binarized = label_binarize(all_labels, classes=np.unique(all_labels))\n",
        "all_preds_binarized = label_binarize(all_preds, classes=np.unique(all_preds))\n",
        "\n",
        "# Compute overall metrics\n",
        "overall_accuracy = accuracy_score(all_labels, all_preds)\n",
        "balanced_accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
        "precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
        "recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "# Compute ROC-AUC Score (one-vs-rest approach for multi-class)\n",
        "roc_auc_ovr = roc_auc_score(all_labels_binarized, all_preds_binarized, multi_class='ovr')\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(all_labels, all_preds, target_names=classes)\n",
        "\n",
        "# Print aggregate metrics\n",
        "print(f'Overall Accuracy: {overall_accuracy:.4f}')\n",
        "print(f'Balanced Accuracy: {balanced_accuracy:.4f}')\n",
        "print(f'Precision (Macro): {precision_macro:.4f}')\n",
        "print(f'Recall (Macro): {recall_macro:.4f}')\n",
        "print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "print(f'ROC-AUC Score (OvR): {roc_auc_ovr:.4f}')\n",
        "print('\\nClassification Report:\\n', class_report)\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g5pRDzYAD7Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heatmap with Percentage Values**"
      ],
      "metadata": {
        "id": "h-BIcXInE356"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming all_labels and all_preds are already defined\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Percentage)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qIid8zFiErZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalized Confusion Matrix**"
      ],
      "metadata": {
        "id": "16trlQdZE7Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tVOTVJmXFCSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}