{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyrvVTwnHiTNumHPvBuzVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RudyMartin/dsai-2024/blob/main/tf_transfer_learning_MobileNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning Using MobileNetV2**\n"
      ],
      "metadata": {
        "id": "w1OeXqBozElK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What this script does**\n",
        "\n",
        "This script trains an AI program to recognize images of rock, paper, and scissors using a method called transfer learning, where it adapts a pre-trained model, MobileNetV2, for this specific task. It processes images to ensure uniformity, enhances them for better learning, and automatically adjusts the training process to achieve the best performance. After training, it evaluates the model's accuracy using new images and provides a visual report showing how well the model performs. Finally, it saves the trained model and displays graphs of the model's learning progress over time. This approach helps the AI learn efficiently and effectively from the images."
      ],
      "metadata": {
        "id": "pOKfxiYGx1VT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "The images for rock, paper, and scissors are uploaded into seperate folders\n",
        "\n",
        "*   Train (80%)\n",
        "*   Test (20%)\n",
        "\n",
        "Note the batch size of 32, so this may throw and error on small sets of pictures."
      ],
      "metadata": {
        "id": "Wk0eJvfvzE_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "mmM2wPwDx2Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record the start time for performance evaluation\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# Initialize Google Drive for storing and accessing data directly\n",
        "drive.mount('/content/gdrive')\n",
        "root_dir = '/content/gdrive/My Drive/'\n",
        "rps_dir = os.path.join(root_dir, 'rps')\n",
        "train_dir = os.path.join(rps_dir, 'train')\n",
        "test_dir = os.path.join(rps_dir, 'test')\n",
        "model_dir = os.path.join(root_dir, 'model')\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Ensure the data directory exists\n",
        "if not os.path.exists(rps_dir):\n",
        "    raise FileNotFoundError(f\"Directory {rps_dir} does not exist.\")\n",
        "print(f\"'rps' directory contents: {os.listdir(rps_dir)}\")"
      ],
      "metadata": {
        "id": "5_OGOsJ-xorf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom preprocessing function to ensure uniform image sizes and shapes\n",
        "def make_square_and_resize(image):\n",
        "    \"\"\"Pad an image to make it square and resize it to (224, 224).\"\"\"\n",
        "    target_size = (224, 224)\n",
        "    height, width = image.shape[:2]\n",
        "    delta_w = max(height - width, 0)\n",
        "    delta_h = max(width - height, 0)\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "    color = [255, 255, 255]  # white background for padding\n",
        "    new_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "    new_img = cv2.resize(new_img, target_size)\n",
        "    return new_img\n",
        "\n",
        "# Prepare image data generators with real-time augmentation and custom preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=make_square_and_resize\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=make_square_and_resize)\n",
        "\n",
        "# Load images from directories and prepare them for training and validation\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "dWiDR8KKxjqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the CNN model using MobileNetV2 as a base model for transfer learning\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the convolutional base\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions, name='RPS_MobileNetV2')\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Configure callbacks for saving the best model and early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(os.path.join(model_dir, 'best_model.h5'), save_best_only=True)\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator),\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "pVx8ZeoKxY-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using test data and generate detailed classification metrics\n",
        "def evaluate_model(generator, model):\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    for images, labels in generator:\n",
        "        preds = model.predict(images)\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "        if len(all_labels) >= len(generator.labels):  # Prevent infinite loop\n",
        "            break\n",
        "    y_pred = np.argmax(np.array(all_preds), axis=1)\n",
        "    y_true = np.argmax(np.array(all_labels), axis=1)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=generator.class_indices.keys(), yticklabels=generator.class_indices.keys())\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=generator.class_indices.keys()))\n",
        "\n",
        "evaluate_model(test_generator, model)"
      ],
      "metadata": {
        "id": "7lvmhCWzxSPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model for later use or deployment\n",
        "model.save(os.path.join(model_dir, model.name), save_format='tf')"
      ],
      "metadata": {
        "id": "ftKgh1wxxMYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the training history to understand the learning trend\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], 'bo-', label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], 'bo-', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and print the total execution time\n",
        "end_time = datetime.datetime.now()\n",
        "duration = end_time - start_time\n",
        "print(f\"Execution time: {str(duration)}\")"
      ],
      "metadata": {
        "id": "otFKU5AExG_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}