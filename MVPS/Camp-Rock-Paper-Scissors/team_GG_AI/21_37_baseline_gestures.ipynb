{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RudyMartin/dsai-2024/blob/main/MVPS/Camp-Rock-Paper-Scissors/team_GG_AI/21_37_baseline_gestures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSAI Gestures Games AI Startup Project"
      ],
      "metadata": {
        "id": "5Xa8QRmvb520"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Friday morning changes:\n",
        "\n",
        "\n",
        "*   corrected missing initial_learning_rate and fine_tune_learning_rate\n",
        "*   fixed h(history) type in evaluate model step\n",
        "*   replaced rps with gesture classes in confusion matrix\n",
        "*   replaced gestures with class_labels in several places\n",
        "\n",
        "\n",
        "PLEASE RUN THIS WITH REAL DATA\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fWPmd8xWB_VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow opencv-python"
      ],
      "metadata": {
        "id": "BSNw8bB_oUhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Config Project Folder\n",
        "import os\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "# Record the start time for performance evaluation\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "!rm -rf /tmp/*\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/dsai-2024/MVPS\"\n",
        "proj_dir = os.path.join(root_dir, 'Camp-Rock-Paper-Scissors')\n",
        "os.chdir('/content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors')\n",
        "import os\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "# Record the start time for performance evaluation\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "!rm -rf /tmp/*\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/dsai-2024/MVPS\"\n",
        "proj_dir = os.path.join(root_dir, 'Camp-Rock-Paper-Scissors')\n",
        "os.chdir('/content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors')\n",
        "\n",
        "## PLEASE REPOINT THIS NEXT LINE TO YOUR DATA\n",
        "rps_dir = os.path.join(proj_dir, 'gestures')  # this points to data folder\n",
        "train_dir = os.path.join(rps_dir, 'train')\n",
        "test_dir = os.path.join(rps_dir, 'test')\n",
        "model_dir = os.path.join(rps_dir, 'model')\n",
        "base_dir = rps_dir\n",
        "\n",
        "# Create directories for train, test, and model activities\n",
        "for dir in ['train', 'test', 'model']:\n",
        "    os.makedirs(os.path.join(rps_dir, dir), exist_ok=True)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = {\n",
        "    0: \"up\",\n",
        "    1: \"down\",\n",
        "    2: \"left\",\n",
        "    3: \"right\",\n",
        "    4: \"neutral\"  # Add more labels as needed\n",
        "}\n",
        "\n",
        "# Create directories for each class in train and test\n",
        "for label_name in class_labels.values():\n",
        "    os.makedirs(os.path.join(train_dir, label_name.lower()), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, label_name.lower()), exist_ok=True)\n",
        "\n",
        "# Record the end time and calculate the elapsed time\n",
        "end_time = datetime.datetime.now()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time}\")\n",
        "\n",
        "# Look at the current directory\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "694oSs92dJXJ",
        "outputId": "5b9f17b1-1653-477d-d069-f7c161ff52e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/gdrive\n",
            "Elapsed time: 0:00:32.565982\n",
            "\u001b[0m\u001b[01;34mcolab_setup\u001b[0m/  functional_1_acc_graph.png   \u001b[01;34mgestures\u001b[0m/    \u001b[01;34mmodel_tune\u001b[0m/  \u001b[01;34mrps\u001b[0m/      \u001b[01;34mrps_660\u001b[0m/\n",
            "\u001b[01;34mdata_prep\u001b[0m/    functional_1_loss_graph.png  \u001b[01;34mmodel_init\u001b[0m/  README.MD    \u001b[01;34mrps_114\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Set Up Data Collection**\n",
        "We'll write a script to capture images from the webcam and save them into directories corresponding to the five directions: up, down, left, right, and neutral."
      ],
      "metadata": {
        "id": "H9Ed1d6EfhmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "MDVeCORwihZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Directory for saving images\n",
        "# see config above\n",
        "\n",
        "# Create directories for each gesture\n",
        "# see config above\n",
        "\n",
        "def get_unique_filename(directory, gesture, extension='jpg'):\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    base_filename = f\"{gesture}_{timestamp}\"\n",
        "    filename = f\"{base_filename}.{extension}\"\n",
        "    full_path = os.path.join(directory, gesture, filename)\n",
        "    counter = 1\n",
        "    while os.path.exists(full_path):\n",
        "        filename = f\"{base_filename}_{counter}.{extension}\"\n",
        "        full_path = os.path.join(directory, gesture, filename)\n",
        "        counter += 1\n",
        "    return full_path\n",
        "\n",
        "\n",
        "split_dir = train_dir ##. change\n",
        "\n",
        "# Capture and save images\n",
        "for gesture in gestures:\n",
        "    print(f\"Capturing images for {gesture}. Press the 'Capture' button in the displayed UI.\")\n",
        "    for _ in range(2):  # Adjust the range for more images\n",
        "        unique_filename = get_unique_filename(split_dir, gesture)\n",
        "        filename = take_photo(unique_filename)\n",
        "        print(f\"Saved {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Mk0mi7PEihlH",
        "outputId": "4c63aa43-0a55-40ed-bb47-f027a224b43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capturing images for up. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/up/up_20240808_164017.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/up/up_20240808_164029.jpg\n",
            "Capturing images for down. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/down/down_20240808_164043.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/down/down_20240808_164053.jpg\n",
            "Capturing images for left. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/left/left_20240808_164106.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/left/left_20240808_164116.jpg\n",
            "Capturing images for right. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/right/right_20240808_164125.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/right/right_20240808_164138.jpg\n",
            "Capturing images for neutral. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/neutral/neutral_20240808_164145.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/neutral/neutral_20240808_164157.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Dictionary of class labels and corresponding directories\n",
        "class_labels = {\n",
        "    0: \"up\",\n",
        "    1: \"down\",\n",
        "    2: \"left\",\n",
        "    3: \"right\",\n",
        "    4: \"neutral\"  # Add more labels as needed\n",
        "}\n",
        "\n",
        "dirs = {\n",
        "    'Train': train_dir,\n",
        "    'Test': test_dir\n",
        "}\n",
        "\n",
        "# Nested loop to count images and print results\n",
        "for dir_type, dir_path in dirs.items():\n",
        "    print(f\"{dir_type} directory: {dir_path}\")\n",
        "    for label_index, label_name in class_labels.items():\n",
        "        num_images = len(glob.glob(f'{dir_path}/{label_name.lower()}/*.jpg'))\n",
        "        print(f\"Number of {dir_type.lower()} {label_name.lower()} images: {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVp0PC1Mw4gW",
        "outputId": "541f030c-bc8a-4ad4-fa74-7da0b1401139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train directory: /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train\n",
            "Number of train up images: 50\n",
            "Number of train down images: 50\n",
            "Number of train left images: 50\n",
            "Number of train right images: 50\n",
            "Number of train neutral images: 50\n",
            "Test directory: /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/test\n",
            "Number of test up images: 0\n",
            "Number of test down images: 0\n",
            "Number of test left images: 0\n",
            "Number of test right images: 0\n",
            "Number of test neutral images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Prepare the Dataset**\n",
        "\n",
        "After collecting enough images for each gesture, prepare the dataset for training."
      ],
      "metadata": {
        "id": "3FITu8nccctn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MobileNetV2 model expects input images to be 128x128 pixels with 3 color channels (RGB), but your training data has images of size 64x64 pixels. So set that in fthe function call."
      ],
      "metadata": {
        "id": "eCYsOPU67Fmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = {\n",
        "    0: \"up\",\n",
        "    1: \"down\",\n",
        "    2: \"left\",\n",
        "    3: \"right\",\n",
        "    4: \"neutral\"  # Add more labels as needed\n",
        "}\n",
        "\n",
        "def load_data(base_dir, img_size=(128, 128)):\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {label_name.lower(): i for i, label_name in class_labels.items()}\n",
        "\n",
        "    for label_name in label_map.keys():\n",
        "        gesture_dir = os.path.join(base_dir, label_name)\n",
        "        for img_name in os.listdir(gesture_dir):\n",
        "            img_path = os.path.join(gesture_dir, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Read image in color mode\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(label_map[label_name])\n",
        "\n",
        "    X = np.array(X, dtype='float32') / 255.0\n",
        "    y = np.array(y, dtype='int')\n",
        "\n",
        "    y = to_categorical(y, num_classes=len(class_labels))\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Load and split the data\n",
        "X_train, X_test, y_train, y_test = load_data(train_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "g2xyaHLqb4uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Fmzir-YR5sMx",
        "outputId": "ef7a552a-c0d7-48c8-e0c0-773fafffb0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Define, Train and Compile the Model**\n",
        "\n",
        "Proceed with the model definition and training as usual. The seeds set earlier will ensure that the training process is reproducible."
      ],
      "metadata": {
        "id": "qdhZKeLtBkOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load MobileNetV2 with pre-trained weights, exclude top layers\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model_name = \"testeval_v001\"\n",
        "time_stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base_model layers so they are not trained\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model with an initial learning rate\n",
        "initial_learning_rate = 0.001\n",
        "model.compile(optimizer=Adam(learning_rate=initial_learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=32)\n",
        "\n",
        "# Unfreeze the base_model layers and fine-tune the entire model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile the model with a lower learning rate for fine-tuning\n",
        "fine_tune_learning_rate = 0.0001\n",
        "model.compile(optimizer=Adam(learning_rate=fine_tune_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Configure callbacks for saving the best model and early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_file = f'best_{model_name}_{time_stamp}.keras'\n",
        "model_checkpoint = ModelCheckpoint(os.path.join(model_dir, {model_file}), save_best_only=True)\n",
        "# Train the model and get the history object\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping, model_checkpoint],\n",
        "                    epochs=4,\n",
        "                    batch_size=32)\n",
        "\n",
        "# Save the model\n",
        "#model_dir = 'override_model_directory'  # Specify your model directory if needed\n",
        "#model_name = \"testeval_v001\"\n",
        "#time_stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "#model.save(f'{model_dir}/{model_name}_{time_stamp}.keras')\n",
        "\n",
        "# OPTIONAL: Save the weights to file also\n",
        "#time_stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "#weights_file = f'{model_dir}/{model_name}_{time_stamp}_weights.keras'\n",
        "#model.save_weights(weights_file)\n"
      ],
      "metadata": {
        "id": "16eQ1c1xb45N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9177d28c-80f5-4cae-aaed-25ea73c077cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.1580 - loss: 2.3496 - val_accuracy: 0.4600 - val_loss: 1.3315\n",
            "Epoch 2/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 415ms/step - accuracy: 0.6394 - loss: 1.0637 - val_accuracy: 0.7200 - val_loss: 0.8692\n",
            "Epoch 3/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 484ms/step - accuracy: 0.8774 - loss: 0.6349 - val_accuracy: 0.8400 - val_loss: 0.6128\n",
            "Epoch 4/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 658ms/step - accuracy: 0.9342 - loss: 0.3931 - val_accuracy: 0.8600 - val_loss: 0.5153\n",
            "Epoch 1/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.4610 - loss: 1.6419 - val_accuracy: 0.3200 - val_loss: 5.2201\n",
            "Epoch 2/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8884 - loss: 0.3555 - val_accuracy: 0.5800 - val_loss: 4.3676\n",
            "Epoch 3/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.9454 - loss: 0.1880 - val_accuracy: 0.5400 - val_loss: 6.8514\n",
            "Epoch 4/4\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4s/step - accuracy: 0.9927 - loss: 0.0410 - val_accuracy: 0.4800 - val_loss: 7.9202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLEASE FIX THIS"
      ],
      "metadata": {
        "id": "6yThrIQciKX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5: Evaluate the Model**"
      ],
      "metadata": {
        "id": "5AjGJ3LrAK9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate_model(generator, model):\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    for images, labels in generator:\n",
        "        preds = model.predict(images)\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "        if len(all_labels) >= len(generator.labels):  # Prevent infinite loop\n",
        "            break\n",
        "    y_pred = np.argmax(np.array(all_preds), axis=1)\n",
        "    y_true = np.argmax(np.array(all_labels), axis=1)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=generator.class_indices.keys(), yticklabels=generator.class_indices.keys())\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=generator.class_indices.keys()))\n",
        "\n",
        "# Load your model (replace with your actual model path to override prior selection)\n",
        "#model_name=\"mobilenetv2_head_gesture_model\"\n",
        "model1 = load_model(f'{model_dir}/{model_name}.keras')\n",
        "\n",
        "# Define the test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{test_dir}',  # Adjust the path to your test data directory\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Ensure shuffle is set to False for proper evaluation\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(test_generator, model1)\n"
      ],
      "metadata": {
        "id": "FmSQiuaob5Eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "af3cf188-9e56-4790-e107-3d96c2a771d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=/content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/model/mobilenetv2_head_gesture_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4a1c43824692>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Load your model (replace with your actual model path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mobilenetv2_head_gesture_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_dir}/{model_name}.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Define the test data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/model/mobilenetv2_head_gesture_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Evaluate Model\n",
        "\n",
        "# helper functions\n",
        "def show_scores1(model, h, X_train, y_train, X_test, y_test):\n",
        "    loss, acc = model.evaluate(X_train, Y_train, verbose=0)\n",
        "    print (\"Training: accuracy   = %.6f loss = %.6f\" % (acc, loss))\n",
        "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print (\"Validation: accuracy = %.6f loss = %.6f\" % (acc, loss))\n",
        "    if 'val_acc' in h.history:\n",
        "        print (\"Over fitting score   = %.6f\" % over_fitting_score(h))\n",
        "        print (\"Under fitting score  = %.6f\" % under_fitting_score(h))\n",
        "    print (\"Params count:\", model.count_params())\n",
        "    print (\"stop epoch =\", max(h.epoch))\n",
        "    print (\"nb_epoch =\", h.params['epochs'])\n",
        "    #print (\"batch_size =\", h.params['batch_size'])\n",
        "    #print (\"nb_sample =\", h.params['samples'])\n",
        "    view_acc1(h)\n",
        "    id = model.name[-1]\n",
        "    plt.savefig(model.name + '_acc_graph.png')\n",
        "    plt.show()\n",
        "    view_loss(h)\n",
        "    plt.savefig(model.name + '_loss_graph.png')\n",
        "    plt.show()\n",
        "\n",
        "def view_acc1(h):\n",
        "    # Accuracy history graph\n",
        "    plt.plot(h.history['accuracy'])\n",
        "    if 'val_accuracy' in h.history:\n",
        "        plt.plot(h.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    leg = plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.setp(leg.get_lines(), linewidth=3.0)\n",
        "\n",
        "def view_loss(h):\n",
        "    # Loss history graph\n",
        "    plt.plot(h.history['loss'])\n",
        "    if 'val_loss' in h.history:\n",
        "        plt.plot(h.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    leg = plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.setp(leg.get_lines(), linewidth=3.0)\n",
        "\n",
        " ## print both model accuracy and model loss by epoch\n",
        "show_scores1(model1, history, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "kSook8D9D4f1",
        "outputId": "dd3368b7-68ea-4dfc-937f-0e944311364e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a77bfadedc07>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m  \u001b[0;31m## print both model accuracy and model loss by epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mshow_scores1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CONFUSION MATRIX** :  Contains True versus Predicted Vakues\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, f1_score, matthews_corrcoef, jaccard_score\n",
        "\n",
        "# Define class labels\n",
        "class_labels = {\n",
        "    0: \"up\",\n",
        "    1: \"down\",\n",
        "    2: \"left\",\n",
        "    3: \"right\",\n",
        "    4: \"neutral\"  # Add more labels as needed\n",
        "}\n",
        "\n",
        "# Make predictions\n",
        "predict_x = model1.predict(X_test)\n",
        "y_pred = np.argmax(predict_x, axis=1)\n",
        "\n",
        "# Convert numerical labels to class names\n",
        "y_test_labels = [class_labels[int(y)] for y in y_test]\n",
        "y_pred_labels = [class_labels[int(y)] for y in y_pred]\n",
        "\n",
        "true_preds = [(x, y, p) for (x, y, p) in zip(X_test, y_test_labels, y_pred_labels) if y == p]\n",
        "false_preds = [(x, y, p) for (x, y, p) in zip(X_test, y_test_labels, y_pred_labels) if y != p]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classes = np.array(list(class_labels.values()))\n",
        "\n",
        "# Initialize the metrics dictionary\n",
        "metrics = {\n",
        "    'Class': [],\n",
        "    'TP': [],\n",
        "    'FN': [],\n",
        "    'FP': [],\n",
        "    'TN': [],\n",
        "    'Recall': [],\n",
        "    'Precision': [],\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Specificity': [],\n",
        "    'MCC': [],\n",
        "    'Jaccard Index': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each class\n",
        "for i, class_label in enumerate(classes):\n",
        "    TP = conf_matrix[i, i]\n",
        "    FN = conf_matrix[i, :].sum() - TP\n",
        "    FP = conf_matrix[:, i].sum() - TP\n",
        "    TN = conf_matrix.sum() - (TP + FN + FP)\n",
        "\n",
        "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
        "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if TP + TN + FP + FN != 0 else 0\n",
        "    f1 = f1_score(y_test_labels, y_pred_labels, labels=[class_label], average=None)[0]\n",
        "    specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
        "    mcc = matthews_corrcoef(y_test_labels, y_pred_labels)\n",
        "    jaccard = jaccard_score(y_test_labels, y_pred_labels, labels=[class_label], average=None)[0]\n",
        "\n",
        "    metrics['Class'].append(class_label)\n",
        "    metrics['TP'].append(TP)\n",
        "    metrics['FN'].append(FN)\n",
        "    metrics['FP'].append(FP)\n",
        "    metrics['TN'].append(TN)\n",
        "    metrics['Recall'].append(recall)\n",
        "    metrics['Precision'].append(precision)\n",
        "    metrics['Accuracy'].append(accuracy)\n",
        "    metrics['F1 Score'].append(f1)\n",
        "    metrics['Specificity'].append(specificity)\n",
        "    metrics['MCC'].append(mcc)\n",
        "    metrics['Jaccard Index'].append(jaccard)\n",
        "\n",
        "# Convert metrics dictionary to DataFrame\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "# Show the DataFrame with all metrics\n",
        "print(df_metrics)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "time_stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "df_metrics.to_csv(f\"df_metrics_{model_name}_{time_stamp}.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "4xhG4-yyFXHf",
        "outputId": "99cb932e-d902-4a97-df07-86b115ac6f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "as_list() is not defined on an unknown TensorShape.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2e1415e15995>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredict_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Unmount your drive when finished\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "sa3-AVTEtwgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}