{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTA3hUb2zw+DActhc9kRPw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RudyMartin/dsai-2024/blob/main/MVPS/Camp-Rock-Paper-Scissors/gestures/baseline_gestures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSAI Gestures Games AI Startup Project"
      ],
      "metadata": {
        "id": "5Xa8QRmvb520"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python"
      ],
      "metadata": {
        "id": "BSNw8bB_oUhT",
        "outputId": "37a85eb1-29f0-4b8b-d112-8339a925bc84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Config Project Folder\n",
        "import os\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "# Record the start time for performance evaluation\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "!rm -rf /tmp/*\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/dsai-2024/MVPS\"\n",
        "proj_dir = os.path.join(root_dir, 'Camp-Rock-Paper-Scissors')\n",
        "os.chdir('/content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors')\n",
        "\n",
        "## PLEASE REPOINT THIS NEXT LINE TO YOUR DATA\n",
        "rps_dir = os.path.join(proj_dir, 'gestures') # this points to data folder\n",
        "train_dir = os.path.join(rps_dir, 'train')\n",
        "test_dir = os.path.join(rps_dir, 'test')\n",
        "model_dir = os.path.join(rps_dir, 'model')\n",
        "base_dir=rps_dir\n",
        "\n",
        "# Create directories for train, test, and model activities\n",
        "for dir in ['train', 'test', 'model']:\n",
        "    os.makedirs(os.path.join(rps_dir, dir), exist_ok=True)\n",
        "\n",
        "# Define and create directories for classes\n",
        "gestures = ['up', 'down', 'left', 'right', 'neutral']\n",
        "for gesture in gestures:\n",
        "    os.makedirs(os.path.join(train_dir, gesture), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, gesture), exist_ok=True)\n",
        "\n",
        "# Record the end time and calculate the elapsed time\n",
        "end_time = datetime.datetime.now()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time}\")\n",
        "\n",
        "## Look at the current directory\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "694oSs92dJXJ",
        "outputId": "980305df-596e-49c5-8605-10ab668df5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/gdrive\n",
            "Elapsed time: 0:00:27.689644\n",
            "\u001b[0m\u001b[01;34mcolab_setup\u001b[0m/  \u001b[01;34mgestures\u001b[0m/    \u001b[01;34mmodel_tune\u001b[0m/  \u001b[01;34mrps\u001b[0m/      \u001b[01;34mrps_321\u001b[0m/        \u001b[01;34mrps_660\u001b[0m/\n",
            "\u001b[01;34mdata_prep\u001b[0m/    \u001b[01;34mmodel_init\u001b[0m/  README.MD    \u001b[01;34mrps_114\u001b[0m/  \u001b[01;34mrps_360_green\u001b[0m/  \u001b[01;34mrps_dir\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvZSHH2ftrlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Set Up Data Collection**\n",
        "We'll write a script to capture images from the webcam and save them into directories corresponding to the five directions: up, down, left, right, and neutral."
      ],
      "metadata": {
        "id": "H9Ed1d6EfhmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "MDVeCORwihZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Directory for saving images\n",
        "# see config above\n",
        "\n",
        "# Create directories for each gesture\n",
        "# see config above\n",
        "\n",
        "def get_unique_filename(directory, gesture, extension='jpg'):\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    base_filename = f\"{gesture}_{timestamp}\"\n",
        "    filename = f\"{base_filename}.{extension}\"\n",
        "    full_path = os.path.join(directory, gesture, filename)\n",
        "    counter = 1\n",
        "    while os.path.exists(full_path):\n",
        "        filename = f\"{base_filename}_{counter}.{extension}\"\n",
        "        full_path = os.path.join(directory, gesture, filename)\n",
        "        counter += 1\n",
        "    return full_path\n",
        "\n",
        "\n",
        "split_dir = train_dir ##. change\n",
        "\n",
        "# Capture and save images\n",
        "for gesture in gestures:\n",
        "    print(f\"Capturing images for {gesture}. Press the 'Capture' button in the displayed UI.\")\n",
        "    for _ in range(2):  # Adjust the range for more images\n",
        "        unique_filename = get_unique_filename(split_dir, gesture)\n",
        "        filename = take_photo(unique_filename)\n",
        "        print(f\"Saved {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Mk0mi7PEihlH",
        "outputId": "4921c00c-a0a3-403f-d6c1-e2b24bdc75c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capturing images for up. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/up/up_20240808_024829.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/up/up_20240808_024836.jpg\n",
            "Capturing images for down. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/down/down_20240808_024839.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/down/down_20240808_024842.jpg\n",
            "Capturing images for left. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/left/left_20240808_024844.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/left/left_20240808_024849.jpg\n",
            "Capturing images for right. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/right/right_20240808_024851.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/right/right_20240808_024854.jpg\n",
            "Capturing images for neutral. Press the 'Capture' button in the displayed UI.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/neutral/neutral_20240808_024856.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train/neutral/neutral_20240808_024903.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##. Validate Data Exists\n",
        "import glob\n",
        "\n",
        "# Labels and corresponding directories\n",
        "labels = ['up', 'down', 'left', 'right', 'neutral']\n",
        "dirs = {\n",
        "    'Train': train_dir,\n",
        "    'Test': test_dir\n",
        "}\n",
        "\n",
        "# Nested loop to count images and print results\n",
        "for dir_type, dir_path in dirs.items():\n",
        "    print(f\"{dir_type} directory: {dir_path}\")\n",
        "    for label in labels:\n",
        "        num_images = len(glob.glob(f'{dir_path}/{label}/*.jpg'))\n",
        "        print(f\"Number of {dir_type.lower()} {label} images: {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVp0PC1Mw4gW",
        "outputId": "c48efeaf-2d66-4dc0-ceb0-c857c5e99abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train directory: /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/train\n",
            "Number of train up images: 4\n",
            "Number of train down images: 4\n",
            "Number of train left images: 4\n",
            "Number of train right images: 4\n",
            "Number of train neutral images: 4\n",
            "Test directory: /content/gdrive/My Drive/dsai-2024/MVPS/Camp-Rock-Paper-Scissors/gestures/test\n",
            "Number of test up images: 1\n",
            "Number of test down images: 1\n",
            "Number of test left images: 1\n",
            "Number of test right images: 1\n",
            "Number of test neutral images: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Prepare the Dataset**\n",
        "\n",
        "After collecting enough images for each gesture, prepare the dataset for training."
      ],
      "metadata": {
        "id": "3FITu8nccctn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MobileNetV2 model expects input images to be 128x128 pixels with 3 color channels (RGB), but your training data has images of size 64x64 pixels. So set that in fthe function call."
      ],
      "metadata": {
        "id": "eCYsOPU67Fmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "def load_data(base_dir, img_size=(128, 128)):\n",
        "    X = []\n",
        "    y = []\n",
        "    gestures = ['up', 'down', 'left', 'right', 'neutral']\n",
        "    label_map = {gesture: i for i, gesture in enumerate(gestures)}\n",
        "\n",
        "    for gesture in gestures:\n",
        "        gesture_dir = os.path.join(base_dir, gesture)\n",
        "        for img_name in os.listdir(gesture_dir):\n",
        "            img_path = os.path.join(gesture_dir, img_name)\n",
        "            #img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Read image in color mode\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(label_map[gesture])\n",
        "\n",
        "    X = np.array(X, dtype='float32') / 255.0\n",
        "    y = np.array(y, dtype='int')\n",
        "\n",
        "    X = np.expand_dims(X, axis=-1)  # Add channel dimension\n",
        "    y = to_categorical(y, num_classes=len(gestures))\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Load and split the data\n",
        "\n",
        "X_train, X_test, y_train, y_test = load_data(train_dir)\n"
      ],
      "metadata": {
        "id": "g2xyaHLqb4uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Define, Train and Compile the Model**\n",
        "\n",
        "Proceed with the model definition and training as usual. The seeds set earlier will ensure that the training process is reproducible."
      ],
      "metadata": {
        "id": "qdhZKeLtBkOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load MobileNetV2 with pre-trained weights, exclude top layers\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base_model layers so they are not trained\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "# Unfreeze the base_model layers and fine-tune the entire model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile the model with a lower learning rate\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and get the history object\n",
        "h = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=32)\n",
        "\n",
        "# Save the model\n",
        "model_name=\"mobilenetv2_head_gesture_model\"\n",
        "model.save(f'{model_dir}/{model_name}.keras')\n"
      ],
      "metadata": {
        "id": "16eQ1c1xb45N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74d3835-0674-430a-bea4-3f464b514266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.2000 - loss: 1.8265 - val_accuracy: 0.6000 - val_loss: 1.3823\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950ms/step - accuracy: 0.5000 - loss: 1.3934 - val_accuracy: 0.6000 - val_loss: 1.1492\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - accuracy: 0.6500 - loss: 1.0984 - val_accuracy: 0.6000 - val_loss: 0.9628\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - accuracy: 0.8000 - loss: 0.8230 - val_accuracy: 0.8000 - val_loss: 0.8743\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - accuracy: 0.9000 - loss: 0.6446 - val_accuracy: 0.8000 - val_loss: 0.8319\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.9500 - loss: 0.5265 - val_accuracy: 0.8000 - val_loss: 0.7717\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 1.0000 - loss: 0.4270 - val_accuracy: 0.8000 - val_loss: 0.6562\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step - accuracy: 1.0000 - loss: 0.3232 - val_accuracy: 1.0000 - val_loss: 0.5410\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step - accuracy: 1.0000 - loss: 0.2452 - val_accuracy: 1.0000 - val_loss: 0.4542\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 0.1972 - val_accuracy: 1.0000 - val_loss: 0.3908\n",
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43s/step - accuracy: 0.3500 - loss: 1.9440 - val_accuracy: 0.8000 - val_loss: 0.4642\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.1030 - val_accuracy: 0.4000 - val_loss: 0.8864\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.4000 - val_loss: 1.5310\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.4000 - val_loss: 1.9615\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.4000 - val_loss: 2.2233\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.4000 - val_loss: 2.3345\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4000 - val_loss: 2.4838\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4000 - val_loss: 2.6564\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.4000 - val_loss: 2.8060\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.1732e-04 - val_accuracy: 0.4000 - val_loss: 2.9222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KhkqWwjvhf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLEASE FIX THIS"
      ],
      "metadata": {
        "id": "6yThrIQciKX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5: Evaluate the Model**"
      ],
      "metadata": {
        "id": "5AjGJ3LrAK9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate_model(generator, model):\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    for images, labels in generator:\n",
        "        preds = model.predict(images)\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "        if len(all_labels) >= len(generator.labels):  # Prevent infinite loop\n",
        "            break\n",
        "    y_pred = np.argmax(np.array(all_preds), axis=1)\n",
        "    y_true = np.argmax(np.array(all_labels), axis=1)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=generator.class_indices.keys(), yticklabels=generator.class_indices.keys())\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=generator.class_indices.keys()))\n",
        "\n",
        "# Load your model (replace with your actual model path)\n",
        "model_name=\"mobilenetv2_head_gesture_model\"\n",
        "model1 = load_model(f'{model_dir}/{model_name}.keras')\n",
        "\n",
        "# Define the test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    f'{test_dir}',  # Adjust the path to your test data directory\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Ensure shuffle is set to False for proper evaluation\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(test_generator, model1)\n"
      ],
      "metadata": {
        "id": "FmSQiuaob5Eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51d04afb-fd54-424a-d868-31b148a92c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 images belonging to 5 classes.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        down       0.00      0.00      0.00         1\n",
            "        left       0.00      0.00      0.00         1\n",
            "     neutral       0.00      0.00      0.00         1\n",
            "       right       0.00      0.00      0.00         1\n",
            "          up       0.25      1.00      0.40         1\n",
            "\n",
            "    accuracy                           0.20         5\n",
            "   macro avg       0.05      0.20      0.08         5\n",
            "weighted avg       0.05      0.20      0.08         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Evaluate Model\n",
        "\n",
        "# helper functions\n",
        "def show_scores1(model, h, X_train, Y_train, X_test, Y_test):\n",
        "    loss, acc = model.evaluate(X_train, Y_train, verbose=0)\n",
        "    print (\"Training: accuracy   = %.6f loss = %.6f\" % (acc, loss))\n",
        "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print (\"Validation: accuracy = %.6f loss = %.6f\" % (acc, loss))\n",
        "    if 'val_acc' in h.history:\n",
        "        print (\"Over fitting score   = %.6f\" % over_fitting_score(h))\n",
        "        print (\"Under fitting score  = %.6f\" % under_fitting_score(h))\n",
        "    print (\"Params count:\", model.count_params())\n",
        "    print (\"stop epoch =\", max(h.epoch))\n",
        "    print (\"nb_epoch =\", h.params['epochs'])\n",
        "    #print (\"batch_size =\", h.params['batch_size'])\n",
        "    #print (\"nb_sample =\", h.params['samples'])\n",
        "    view_acc1(h)\n",
        "    id = model.name[-1]\n",
        "    plt.savefig(model.name + '_acc_graph.png')\n",
        "    plt.show()\n",
        "    view_loss(h)\n",
        "    plt.savefig(model.name + '_loss_graph.png')\n",
        "    plt.show()\n",
        "\n",
        "def view_acc1(h):\n",
        "    # Accuracy history graph\n",
        "    plt.plot(h.history['accuracy'])\n",
        "    if 'val_accuracy' in h.history:\n",
        "        plt.plot(h.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    leg = plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.setp(leg.get_lines(), linewidth=3.0)\n",
        "\n",
        "def view_loss(h):\n",
        "    # Loss history graph\n",
        "    plt.plot(h.history['loss'])\n",
        "    if 'val_loss' in h.history:\n",
        "        plt.plot(h.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    leg = plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.setp(leg.get_lines(), linewidth=3.0)\n",
        "\n",
        " ## print both model accuracy and model loss by epoch\n",
        "show_scores1(model1, h, X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "kSook8D9D4f1",
        "outputId": "dd3368b7-68ea-4dfc-937f-0e944311364e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a77bfadedc07>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m  \u001b[0;31m## print both model accuracy and model loss by epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mshow_scores1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Unmount your drive when finished\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "Ash785MAttQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CONFUSION MATRIX** :  Contains True versus Predicted Vakues\n",
        "\n",
        "# Define classes\n",
        "class_name = {\n",
        "    0: 'scissor',\n",
        "    1: 'rock',\n",
        "    2: 'paper'\n",
        "}\n",
        "\n",
        "# Make predictions\n",
        "predict_x = model1.predict(X_test)\n",
        "y_pred = np.argmax(predict_x, axis=1)\n",
        "\n",
        "# Convert numerical labels to class names\n",
        "y_test_labels = [class_name[int(y)] for y in y_test]\n",
        "y_pred_labels = [class_name[int(y)] for y in y_pred]\n",
        "\n",
        "true_preds = [(x, y, p) for (x, y, p) in zip(X_test, y_test_labels, y_pred_labels) if y == p]\n",
        "false_preds = [(x, y, p) for (x, y, p) in zip(X_test, y_test_labels, y_pred_labels) if y != p]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classes = np.array(list(class_name.values()))\n",
        "\n",
        "# Initialize the metrics dictionary\n",
        "metrics = {\n",
        "    'Class': [],\n",
        "    'TP': [],\n",
        "    'FN': [],\n",
        "    'FP': [],\n",
        "    'TN': [],\n",
        "    'Recall': [],\n",
        "    'Precision': [],\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Specificity': [],\n",
        "    'MCC': [],\n",
        "    'Jaccard Index': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each class\n",
        "for i, class_label in enumerate(classes):\n",
        "    TP = conf_matrix[i, i]\n",
        "    FN = conf_matrix[i, :].sum() - TP\n",
        "    FP = conf_matrix[:, i].sum() - TP\n",
        "    TN = conf_matrix.sum() - (TP + FN + FP)\n",
        "\n",
        "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
        "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if TP + TN + FP + FN != 0 else 0\n",
        "    f1 = f1_score(y_test_labels, y_pred_labels, labels=[class_label], average=None)[0]\n",
        "    specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
        "    mcc = matthews_corrcoef(y_test_labels, y_pred_labels)\n",
        "    jaccard = jaccard_score(y_test_labels, y_pred_labels, labels=[class_label], average=None)[0]\n",
        "\n",
        "    metrics['Class'].append(class_label)\n",
        "    metrics['TP'].append(TP)\n",
        "    metrics['FN'].append(FN)\n",
        "    metrics['FP'].append(FP)\n",
        "    metrics['TN'].append(TN)\n",
        "    metrics['Recall'].append(recall)\n",
        "    metrics['Precision'].append(precision)\n",
        "    metrics['Accuracy'].append(accuracy)\n",
        "    metrics['F1 Score'].append(f1)\n",
        "    metrics['Specificity'].append(specificity)\n",
        "    metrics['MCC'].append(mcc)\n",
        "    metrics['Jaccard Index'].append(jaccard)\n",
        "\n",
        "# Convert metrics dictionary to DataFrame\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "# Show the DataFrame with all metrics\n",
        "print(df_metrics)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_metrics.to_csv(f\"df_metrics_{model_name}_20240610.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "4xhG4-yyFXHf",
        "outputId": "99cb932e-d902-4a97-df07-86b115ac6f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "as_list() is not defined on an unknown TensorShape.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2e1415e15995>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredict_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Unmount your drive when finished\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "sa3-AVTEtwgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}