{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvCln2WZzTnh0RSochk3kN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RudyMartin/dsai-2024/blob/main/MVPS/Student-Exercises/Explaining_Algorithm_Complexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making  Complexity Easy-to-Explain\n",
        "\n",
        "Here's a simple set of examples to help explain Algorithm Complexity\n",
        "\n",
        "| **Name/Description** | **Math Example** |\n",
        "|----------------------|------------------|\n",
        "| **O(1) - Constant Time** | **Accessing an Array Index**: Given `ARR = [3, 8, 5, 12]`, accessing `ARR[2]` simply returns `5`. |\n",
        "| **O(n) - Linear Time** | **Traversing an Array**: Sum all elements in an array `ARR = [2, 4, 6, 8]`.<br>Equation: \\( \\text{Sum} = 2 + 4 + 6 + 8 = 20 \\)<br>Solution: `20` |\n",
        "| **O(log n) - Logarithmic Time** | **Binary Search**: Find `4` in the sorted array `ARR = [1, 2, 4, 7, 9]`. Start by comparing the middle element.<br>Steps:<br>1. Compare `4` to `4` (middle of the array).<br>2. Found `4` at index 2.<br>Solution: Index `2` |\n",
        "| **O(n log n) - Linearithmic Time** | **Merge Sort**: Sort the array `ARR = [4, 2, 7, 1]`.<br>Steps:<br>1. Split into `[4, 2]` and `[7, 1]`.<br>2. Split further into `[4]`, `[2]`, `[7]`, `[1]`.<br>3. Merge into `[2, 4]` and `[1, 7]`.<br>4. Merge into `[1, 2, 4, 7]`.<br>Solution: `[1, 2, 4, 7]` |\n",
        "| **O(n²) - Quadratic Time** | **Bubble Sort**: Sort `ARR = [4, 3, 2, 1]` by comparing each pair.<br>Steps:<br>1. Compare and swap `4` & `3`, then `4` & `2`, then `4` & `1`. Now `[3, 2, 1, 4]`.<br>2. Repeat process for remaining elements.<br>Solution: `[1, 2, 3, 4]` |\n",
        "| **O(2^n) - Exponential Time**  | **Fibonacci Sequence (Recursive)**: Calculate the 5th Fibonacci number using recursion.<br>Steps:<br>1. \\( F(5) = F(4) + F(3) \\)<br>2. \\( F(4) = F(3) + F(2) \\), \\( F(3) = F(2) + F(1) \\)<br>3. Continue until \\( F(1) = 1 \\), \\( F(0) = 0 \\).<br>Solution: `F(5) = 5` |\n",
        "| **O(n!) - Factorial Time**     | **Permutations**: Find all permutations of `ARR = [1, 2, 3]`.<br>Permutations: `[1, 2, 3]`, `[1, 3, 2]`, `[2, 1, 3]`, `[2, 3, 1]`, `[3, 1, 2]`, `[3, 2, 1]`.<br>Solution: `6` permutations |\n",
        "\n",
        "\n",
        "And if  you are interested  in  more  examples,  these general uses are ordered from the best (fastest) to the worst (slowest):\n",
        "\n",
        "### O(1) Time Complexity (Constant Time)\n",
        "- **Accessing an Array Index**: If you have an array `ARR`, accessing any element like `ARR[5]` takes the same amount of time, regardless of the size of the array.\n",
        "- **Pushing and Popping on Stack**: Adding or removing an element from the top of a stack is done in constant time.\n",
        "- **Inserting a Node in Linked List**: If you already have a reference to the position where you want to insert, it takes constant time to insert a new node.\n",
        "\n",
        "### O(n) Time Complexity (Linear Time)\n",
        "- **Traversing an Array**: To visit each element in an array of size `n`, you need to go through all `n` elements.\n",
        "- **Traversing a Linked List**: Similar to an array, you need to go through each node, taking linear time.\n",
        "- **Linear Search**: To find a specific element, you might have to check every element, leading to O(n) time.\n",
        "- **Checking for a Palindrome**: To check if a word is a palindrome, you have to compare each character from the start and end, leading to linear time.\n",
        "\n",
        "### O(log n) Time Complexity (Logarithmic Time)\n",
        "- **Binary Search**: When searching for an element in a sorted array, you can repeatedly halve the search space. For example, in an array of size 8, you'd only need to check at most 3 elements (log₂8 = 3).\n",
        "- **Finding Largest/Smallest Number in a Binary Search Tree**: By following the right/left child, you can halve the search space at each step.\n",
        "- **Efficient Fibonacci Calculation**: Using techniques like matrix exponentiation or fast doubling, you can calculate Fibonacci numbers in O(log n) time.\n",
        "\n",
        "### O(n log n) Time Complexity (Linearithmic Time)\n",
        "- **Merge Sort**: This sorting algorithm splits the array in half repeatedly (log n times), and then merges the sorted halves back together in linear time.\n",
        "- **Heap Sort**: Like Merge Sort, but uses a heap data structure to sort in O(n log n) time.\n",
        "- **Quick Sort**: Another divide-and-conquer algorithm that, on average, sorts in O(n log n) time.\n",
        "\n",
        "### O(n²) Time Complexity (Quadratic Time)\n",
        "- **Bubble Sort**: In the worst case, you might have to compare each element with every other element, leading to O(n²) time.\n",
        "- **Insertion Sort**: Similarly, each element might need to be compared to every other element in a sorted portion, leading to O(n²).\n",
        "- **Traversing a 2D Array**: If you have a 2D array with `n x n` elements, visiting each one takes O(n²) time.\n",
        "\n",
        "### O(2^n) Time Complexity (Exponential Time)\n",
        "- **Recursive Fibonacci Calculation**: The recursive algorithm to calculate the nth Fibonacci number is a classic example of exponential time complexity. The number of recursive calls doubles with each increment of `n`, leading to O(2^n) time complexity. For instance, to calculate `F(5)`, the algorithm makes recursive calls for `F(4)` and `F(3)`, each of which further splits into more recursive calls, resulting in an exponential growth of operations.\n",
        "- **Exponential Growth Problems**: Any problem where the solution space doubles with each increment in input size, such as finding subsets or combinations, often exhibits exponential time complexity. For example, generating all possible subsets of a set of size `n` requires checking `2^n` possible combinations.\n",
        "\n",
        "### O(n!) Time Complexity (Factorial Time)\n",
        "- **Solving the Traveling Salesman Problem (TSP) via Brute Force**: In this problem, you consider all possible permutations of the cities to find the shortest path. If there are `n` cities, there are `n!` possible routes.\n",
        "- **Generating All Permutations**: If you want to generate all possible permutations of a set, you'll end up with `n!` permutations to consider.\n",
        "- **Finding the Determinant with Laplace Expansion**: This method involves recursive expansion and can lead to factorial time complexity for large matrices.\n",
        "\n",
        "**In Summary:**\n",
        "- **O(1)**: Fastest, constant operations like accessing a specific element in an array.\n",
        "- **O(n)**: Linear operations where you process each element once, like looping through an array.\n",
        "- **O(log n)**: Operations that cut the problem size in half each step, like binary search.\n",
        "- **O(n log n)**: Efficient algorithms that combine linear and logarithmic steps, like merge sort.\n",
        "- **O(n²)**: Slower, brute-force methods where every element is compared with every other element, like bubble sort.\n",
        "- **O(2^n)**: Very slow exponential growth, where the number of operations doubles with each additional input, like recursive Fibonacci calculations.\n",
        "- **O(n!)**: Slowest, factorial time, often in problems involving permutations or combinations, like solving TSP via brute force.\n",
        "\n",
        "These examples help illustrate how the complexity grows as the size of the input increases, affecting the algorithm's efficiency.\n"
      ],
      "metadata": {
        "id": "1SmpDBaBUh7y"
      }
    }
  ]
}